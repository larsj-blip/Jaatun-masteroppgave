\section{Introduction}

One of the enduring challenges in computing is reducing power requirements of computers while also increasing processing power. For many years, decreasing transistor size while increasing the amount of transistors was the best bet for improving processing speed and efficiency, and this has evolved into the ever increasing parallel computing race that we have today. While the largest leaps in processing speed and efficiency have been made on the hardware side, improvements seem to be reaching a plateau. This has encouraged efforts to improve resource usage through software. One such effort is approximate computing. 

\emph{Approximate computing} is used either to reduce power consumption, increase processing speeds, or both at the same time at the cost of the precision of the results. This approximation can be implemented in software, either as less accurate algorithms that are less resource intensive, as a reduction in the amount of significant digits operated on, or using heuristics that can replace or remove sections of code while maintaining a degree of accuracy, or in hardware as accelerators, approximate logic units or approximate storage solutions. For illustration purposes one can liken approximate computing to a greedy graph traversal algorithm, such as the greedy best-first search~\citep{coles2007marvin} that finds a path between two nodes in a graph quickly, but is not guaranteed to find the shortest/optimal path, instead of an algorithm that is guaranteed to find the shortest path, such as Dijkstra's algorithm~\citep{dijkstra1959note}, but is slower to run. This thesis concerns itself with approximate computing implemented in software, not approximate computing in hardware. 

%Critical infrastructure and other critical fields can benefit from approximate computing.
Some fields that can benefit from approximate computing are scientific simulations and IoT-based critical infrastructure components. In simulation and high precision data processing, approximate computing may reduce both time spent on calculations and power consumed at the cost of precision. Weather simulations for use in weather reports are heavy calculations that have to be re-done often due to rapidly changing parameters that change the results, and might therefore benefit from reducing precision and instead increasing the amount of times the simulations are run with updated parameters. Critical infrastructure installations such as hydro power plants or water reservoirs depend more on and more on IoT-devices for monitoring~\citep{watertight_jaatun}. These monitoring nodes are largely comprised of low-powered hardware powered by solar or batteries. Implementing approximate computing for IoT-nodes running on low-power systems may increase longevity of these nodes, reducing operating costs. Image processing and recognition done in modern cars for obstacle detection and avoidance may also benefit from lower power draw and increased processing speed for quicker response to events and lower power consumption leading to longer range. %litt søkt kanskje? kronglete setning. Siter Water-Tight IoT–Just Add Security

To augment applications that are sensitive to failures with approximate computing, a more thorough analysis of how approximate computing techniques affect the dependability of an application is required.

Fault tolerance is in simple terms a measure of how well a service can be provided in the presence of faults. A more accurate description is provided in section~\ref{section:Reliability_thorugh_fault_tolerance}. Fault tolerance is vital for applications with strict operational and developmental requirements such as power plant control systems, nuclear or otherwise, dam control systems, power grid installations, and real time systems with strict operating requirements, such as self driving cars or aviation equipment. In the worst case, a fault that becomes an error in these fields may result in the loss of life. 

Code quality is important to achieve fault tolerant code, and should be evaluated alongside the operational fault tolerance of a software tool. While the operational aspect is certainly important, i.e., how the code responds to faults that occur during operation, a project's code quality will affect the amount of faults that are created during the developmental phase, which carry equivalent risk of causing service failures during operation. 

There are multiple papers on the investigation of fault tolerance through hardware fault injection, see section~\ref{section:Verifying_fault_tolerance} for a more thorough overview. Hardware fault injection can be performed through ionizing radiation, heat or applying local voltages to the hardware. Fault tolerance experiments such as these are performed mostly to evaluate hardware that will be subjected to harsh conditions. 
Fault injection can also be performed in software. For instance,~\citet{venkatagiri2019gem5} describe a software system that flips individual bits in the program, and simulates the running of these programs to find all bits in a program that are conducive to silent data corruptions (failures that don't stop the service delivery, but delivers an incorrect service).  G-SWFIT is a methodology of injecting software faults that would otherwise fall outside of what a programmer would normally catch during testing~\citep{natella2012fault}


None of the above mentioned software fault injection strategies have yet to be put to use to investigate the reliability properties of approximate computing. There are studies on the fault tolerance in approximate computing hardware, but fault tolerance and reliability in software enabled approximate computing lacks a body of scientific work. The aim of this thesis is to create a foundation that may elicit further work in the space.
